--- 
title: Mini-Apps
homec: home 
tutorialc: tutorial 
applicationsc: applications 
benchmarksc: benchmarks selected benchmarksSelected
downloadc: download
toolsc: tools
helpc: help
---

<!-- <ul> -->
<!-- <div id="hpc"><h2>HPC Challenge</h2> -->
<!-- <p> -->
<!-- Our HPC Challenge suit consists of various benchmarks that demonstrate productivity and performance in a -->
<!-- parallel programming system. -->
<!-- </p> -->
<!-- <br> -->

<h1>MiniApps</h1>

<p>The following are a collection of miniApps we have implemented to demonstrate
  the efficacy of the Charm++ model:</p>

<div class="bench-list">
<ul>
<li><a href="#leanmd">LeanMD - molecular dynamics</a></li>
<li><a href="#amr">AMR - adaptive mesh refinement</a></li>
<li><a href="#barnes">Barnes Hut - n-body problem</a></li>
<li><a href="#denselu">DenseLU - matrix solver (HPC Challenge)</a></li>
<li><a href="#hpccg">HPCCG - conjugant gradient (Mantevo)</a></li>
<li><a href="#solver">TS - triangular solver</a></li>
<li><a href="#fft">FFT - one dimensional FFT (HPC Challenge)</a></li>
<li><a href="#random">RA - random access (HPC Challenge)</a></li>
<li><a href="#stream">EP - stream (HPC Challenge)</a></li>
</ul>

<a name="leanmd"></a>
<div class="benchmark">
  <h2>LeandMD</h2>
  <p>LeanMD is a molecular dynamics simulation program written in Charm++. This benchmark 
  simulates the behavior of atoms based on the Lennard-Jones potential, which is an effective 
  potential that describes the interaction between two uncharged molecules or atoms. 
  The computation performed in this code mimics the short-range non-bonded force calculation 
  in NAMD, and resembles the LJ force computation in miniMD benchmark in the Mantevo benchmark suite 
  maintained by Sandia National Laboratories. 
  <p>The force calculation in Lennard-Jones dynamics is done within a cutoff-radius, r<sub>c</sub> for every atom. 
  In LeanMD, the computation is parallelized using a hybrid scheme of spatial and force decomposition. 
  The three-dimensional (3D) simulation space consisting of atoms is divided into cells of dimensions 
  that are equal to the sum of the cutoff distance, r<sub>c</sub> and a margin. In each iteration, 
  force calculations are done for all pairs of atoms that are within the cutoff distance. The force calculation 
  for a pair of cells is assigned to a different set of objects called computes. Based on the forces sent by 
  the computes, the cells perform the force integration and update various properties of their 
  atoms â€“ acceleration, velocity and positions.
  
  <div class="features"><p>Features: Automated load balancing, fault tolerance, multicast manager.</p></div>
  <div class="giturl"><a href="http://charm.cs.illinois.edu/cgi-bin/gitweb.cgi?p=benchmarks/leanmd.git">git://charm.cs.illinois.edu/benchmarks/leanmd.git</a></div>

<center>
  <div id="multi_figure">
    <figure>
      <img src="../figs/leanmd_bgp.png" width=300>
      <img src="../figs/leanmd_bgq.png" width=300>
      <figcaption>Figure: performance of LeandMD on Blue Gene/P and Blue Gene/Q </figcaption>
    </figure>
    <figure>
      <img src="../figs/leanmd_bgq_chkp.png" width=300>
      <img src="../figs/leanmd_bgq_restart.png" width=300>
      <figcaption>Figure: fault tolerant LeandMD on Blue Gene/Q</figcaption>
    </figure>
  </div>
</center>
</div>

<a name="amr"></a>
<div class="benchmark">
  <h2>AMR</h2>
  <p>AMR is mesh restructuring algorithm for adaptive mesh refinement computations. 
  The parallel mesh restructuring algorithm operates in terms of near-neighbor 
  communicatio  among individual blocks, and a single synchronization-only collective. 
  
  <p> Traditional AMR algorithms phrase the design in terms of processors that
  contain many blocks. Instead, we promote blocks to first-class entities that
  act as a virtual pro- cessor. As the mesh is refined or coarsened in AMR, the
  number of blocks will change and traditional algorithms require
  synchronization at these points. However, to enhance productively, we abstract
  the blocks as a collection that dynamically expands and contracts over time.
  Refinement decisions can then be local to each block and propagated as far as
  algorithmically required so blocks are always within one refinement level of
  their neighbors. Because remeshing occurs only at discrete points in the
  simulation time, instead of using collective communication that is proportional
  to the depth of the recursive refinement, we use a scalable termination
  detection mechanism built into our runtime to globally determine when all
  refinement decisions have been finalized. Previous collective methods require
  O(d) rounds of collective communication, where d is the refinement and
  consume O(P) memory per processor to store the results. By utilizing
  termination detection, we consume a negligible amount of memory and communicate
  no data. Besides termination detection, blocks execute completely
  asynchronously, communicating only with neighboring blocks when required.

  <p>Traditional AMR implementations store the quad-tree instance on each
  process consuming O(P) memory and taking O(log N) time for neighbor lookup.
  We organize the blocks into a quad-tree but address each block by their
  location in the tree using bit vectors to represent quadrants recursively.
  It requires only O(#blocks/P) memory per process and O(1) lookup time. It also
  frees the programmer from having to know where the block lies; instead, the
  underly- ing runtime system manages the physical locations of each block and
  provides direct, efficient communication between them. The runtime system can
  then redistribute the blocks periodically without any change to the logic.

  <div class="features"><p>Features: quiescence detection, dynamic chare creation, load balancing.</p></div>
  <div class="giturl"><a href="http://charm.cs.illinois.edu/cgi-bin/gitweb.cgi?p=benchmarks/amr.git">git://charm.cs.illinois.edu/benchmarks/amr.git</a></div>

<center>
  <div id="multi_figure">
    <figure>
      <img src="../figs/amr_out1.png" width=200>
      <img src="../figs/amr_out2.png" width=200>
      <img src="../figs/amr_out3.png" width=200>
      <figcaption>Figure: example simulation of a circular fluid
      advected by a constant velocity field. From left to right, the figure
      displays the fluid density after 2, 572, and 1022 iterations respectively.
      The white squares demonstrate how the mesh is evolving over time.</figcaption>
    </figure>
    <figure>
      <img src="../figs/amr_perf.png" height=300 width=300>
      <img src="../figs/amr_remesh.png" height=300 width=400>
      <figcaption>Figure: performance of AMR on Blue Gene/Q. Left: Timesteps per
      second strong scaling on IBM BG/Q with a max depth of 15. Right:  The
      non-overlapped delay of remeshing in milliseconds. The
      candlestick graphs the minimum and maximum values, the 5th and 95th
      percentile, and the median.</figcaption>
    </figure>
  </div>
</center>
</div>
  
</div>

<a name="barnes"></a>
<div class="benchmark">
  <h2>Barnes-Hut</h2>
  <p> The Barnes-Hut algorithm is a tree-based scheme to compute fast and
  approximate time-series solutions to the N-body problem, where Barnes-Hut
  algorithm for N-body problem is a method of calculating forces on a system
  of N bodies that grows only as N log N. It uses a tree-structured
  hierarchical recursive subdivision of space into cubic cells. Barnes-Hut
  method is widely used in cosmological simulations.

  <p> The N-body problem involves the numerical calculation of the trajectories
  of N point masses (or charges) moving under the influence of a conservative
  force field such as that induced by gravity (or electrical charges).
  In its simplest form, the method models bodies as particles of zero
  extent moving in a collision-less manner. The objective is to calculate the net
  force incident on every particle at discrete time steps. These forces are then
  used to update the velocity and position of each particle, leading into the next time step,
  where the net force on each particle is calculated once more, etc.
  In general, the force may be long-range in nature (as is the case
      with gravity), so that interactions between distant particles must also
  be calculated. Thus, in order to obtain a good approximation to the actual
  solution of a system, O(N<sup>2</sup>) computations must be performed. Given its
  quadratic complexity, the amount of work done by this all-pairs method makes it
  infeasible for systems with large N.

  <p>Barnes and Hut devised a hierarchical N-body method that
  performs significantly fewer computations but at the cost of a greater
  relative error in the computed solution. The method relies on the spatial
  partitioning of the input system of particles, thereby imposing a tree-structure on it.
  Particles that are close to each other in space are grouped into closely related nodes of
  the tree. This allows the approximation of forces on a particle due to a distant group 
  of particles through the multipole moments of that group.
  Note that applying such an approximation to points relatively close to the group
  will result in gross errors of calculation. In such a case, sub-partitions within
  the group are tested for proximity to the point. This technique, applied systematically,
  yields an expected complexity of O(N lg N), making it suitable for
  large systems of particles.


  <div class="giturl"><a href="http://charm.cs.illinois.edu/cgi-bin/gitweb.cgi?p=benchmarks/barnes.git">git://charm.cs.illinois.edu/benchmarks/barnes.git</a></div>
<center>
  <div id="multi_figure">
    <figure>
      <img src="../figs/barnes_concept.png" width=600>
      <figcaption>Time Progression view showing 2 processors executing an
      iteration of Barnes-Hut.</figcaption>
    </figure>
    <figure>
      <img src="../figs/barnes_perf.png"  width=300>
      <figcaption>Performance of Barnes-Hut for 10 and 50 million particle
      systems on Intrepid (IBM BG/P).</figcaption>
    </figure>
  </div>
</center>
</div>

<a name="denselu"></a>
<div class="benchmark">
  <h2>Dense LU</h2>	 	
  <div class="giturl"><a href="http://charm.cs.illinois.edu/cgi-bin/gitweb.cgi?p=benchmarks/charmlu.git">git://charm.cs.illinois.edu/charmlu.git</a></div>
</div>

<a name="hpccg"></a>
<div class="benchmark">
  <h2>hpccg</h2>
  <div class="giturl">https://charm.cs.uiuc.edu/private/gitweb2.cgi?p=users/lifflander/hpccg.git;a=summary</div>
</div>

<a name="solver"></a>
<div class="benchmark">
  <h2>Triangular Solver</h2>
  <p> Solution of sparse triangular systems of linear equations is a
    performance bottleneck in many methods for solving more general sparse
    systems, such as many iterative methods with preconditioners.  The matrix
    is divided into blocks of columns. Each block is analyzed to find its
    independent rows for computation. If there are dense regions below the
    diagonal section (we assume lower triangular for description), they are
    divided into new blocks. Each diagonal block starts the computation with
    its independent parts and waits for its dependency messages from the left.
    Nondiagonal blocks wait for the solution values from their corresponding
    diagonal block, and then start their computation (and receipt of other
    messages). </p>
  <div class="giturl"><a href="http://charm.cs.illinois.edu/cgi-bin/gitweb.cgi?p=benchmarks/triangularsolver.git">git://charm.cs.illinois.edu/benchmarks/triangularsolver.git</a></div>
</div>

<a name="fft"></a>
<div class="benchmark">
  <h2>1D FFT</h2>
  <p> Our implementation of Global FFT takes input size N and performs a
  complex 1D FFT on an NxN matrix where subsequent rows are contiguous data
  elements of a double precision complex vector. Three all-to-all transposes
  are required to perform the FFT and unscramble the data.  All-to-all
  operations are executed via point-to-point messages and external libraries
  (FFTW or ESSL) perform serial FFTs on the rows of the matrix. </p>
  <div class="giturl"><a href="http://charm.cs.illinois.edu/cgi-bin/gitweb.cgi?p=benchmarks/fft-trans.git">git://charm.cs.illinois.edu/benchmarks/fft-trans.git</a></div>
</div>

<a name="random"></a>
<div class="benchmark">
  <h2>Random Access</h2>
  <p> For Random Access benchmark we use the Mesh Streamer library for
    optimizing all-to-all communication on small messages. </p>
  <div class="giturl"><a href="http://charm.cs.illinois.edu/cgi-bin/gitweb.cgi?p=benchmarks/randomAccess.git">git://charm.cs.illinois.edu/benchmarks/randomAccess.git</a></div>
</div>

<a name="stream"></a>
<div class="benchmark">
  <h2>EP Stream</h2>
  <div class="giturl"><a href="http://charm.cs.illinois.edu/cgi-bin/gitweb.cgi?p=benchmarks/hpccstream.git">git://charm.cs.illinois.edu/benchmarks/hpccstream.git</a></div>
</div>

